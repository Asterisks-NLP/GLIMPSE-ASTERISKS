{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glimpse.evaluate.evaluate_common_metrics_samples import evaluate_rouge\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract RSA Scores from PK Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean_scores(path):\n",
    "  obj = pd.read_pickle(path)\n",
    "  results = obj['results']\n",
    "\n",
    "  cons_scores = []\n",
    "  init_cons_scores = []\n",
    "  listener_df_scores = []\n",
    "  speaker_df_scores = []\n",
    "  language_model_proba_df_scores = []\n",
    "  initial_listener_df_scores = []\n",
    "\n",
    "  for i in range(len(results)):\n",
    "    cons_scores.append(results[i]['consensuality_scores'].describe())\n",
    "    init_cons_scores.append(results[i]['initial_consensuality_scores'].describe())\n",
    "    listener_df_scores.append(results[i]['listener_df'].describe())\n",
    "    speaker_df_scores.append(results[i]['speaker_df'].describe())\n",
    "    language_model_proba_df_scores.append(results[i]['language_model_proba_df'].describe())\n",
    "    initial_listener_df_scores.append(results[i]['initial_listener'].describe())\n",
    "\n",
    "\n",
    "  cons_scores_means = []\n",
    "  init_cons_scores_means = []\n",
    "  listener_df_scores_means = []\n",
    "  speaker_df_scores_means = []\n",
    "  language_model_proba_df_scores_means = []\n",
    "  initial_listener_df_scores_means = []\n",
    "\n",
    "  for i in range(len(cons_scores)):\n",
    "    cons_scores_means.append(cons_scores[i].loc['mean'])\n",
    "\n",
    "  for i in range(len(init_cons_scores)):\n",
    "    init_cons_scores_means.append(init_cons_scores[i].loc['mean'])\n",
    "\n",
    "  for i in range(len(listener_df_scores)):\n",
    "    listener_df_scores_means.append(listener_df_scores[i].loc['mean'].aggregate('mean'))\n",
    "\n",
    "  for i in range(len(speaker_df_scores)):\n",
    "    speaker_df_scores_means.append(speaker_df_scores[i].loc['mean'].aggregate('mean'))\n",
    "\n",
    "  for i in range(len(language_model_proba_df_scores)):\n",
    "    language_model_proba_df_scores_means.append(language_model_proba_df_scores[i].loc['mean'].aggregate('mean'))\n",
    "\n",
    "  for i in range(len(initial_listener_df_scores)):\n",
    "    initial_listener_df_scores_means.append(initial_listener_df_scores[i].loc['mean'].aggregate('mean'))\n",
    "\n",
    "\n",
    "  all_scores = np.array([cons_scores_means, init_cons_scores_means, listener_df_scores_means, speaker_df_scores_means, language_model_proba_df_scores_means, initial_listener_df_scores_means]).transpose()\n",
    "  all_scores_df = pd.DataFrame(all_scores, columns=['consensuality_scores', 'initial_consensuality_scores', 'listener_df', 'speaker_df', 'language_model_proba_df', 'initial_listener'])\n",
    "\n",
    "  return all_scores_df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_original_paths = { \n",
    "    \"2017\" : \"output/abstractive/facebook_bart-large-cnn-_-all_reviews_2017-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37.csv-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2018\" : \"output/abstractive/facebook_bart-large-cnn-_-all_reviews_2018-_-top_p_sampling-_-padded-_-2024-12-09-13-08-21-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2019\" : \"output/abstractive/facebook_bart-large-cnn-_-all_reviews_2019-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2020\" : \"output/abstractive/facebook_bart-large-cnn-_-all_reviews_2020-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\"\n",
    "                          }\n",
    "\n",
    "pickle_gpt2_paths = {\n",
    "    \"2017\" : \"output/abstractive/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2017-_-top_p_sampling-_-trimmed-_-2025-02-08-22-07-53-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2018\" : \"output/abstractive/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2018-_-top_p_sampling-_-trimmed-_-2025-02-08-23-18-26-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2019\" : \"output/abstractive/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2019-_-top_p_sampling-_-trimmed-_-2025-02-09-01-34-19-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2020\" : \"output/abstractive/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2020-_-top_p_sampling-_-trimmed-_-2025-02-09-10-18-19-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "mean_scores_original = {}\n",
    "\n",
    "for name, path in pickle_original_paths.items():\n",
    "  print(name)\n",
    "  mean_scores_original[name] =  extract_mean_scores(path).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_listener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.652511</td>\n",
       "      <td>0.182344</td>\n",
       "      <td>-9.367365</td>\n",
       "      <td>-10.816949</td>\n",
       "      <td>-16.605637</td>\n",
       "      <td>-1.837223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1.051409</td>\n",
       "      <td>0.436363</td>\n",
       "      <td>-17.345043</td>\n",
       "      <td>-19.487237</td>\n",
       "      <td>-18.474056</td>\n",
       "      <td>-2.303026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1.053721</td>\n",
       "      <td>0.425736</td>\n",
       "      <td>-16.270704</td>\n",
       "      <td>-18.416813</td>\n",
       "      <td>-18.250831</td>\n",
       "      <td>-2.196775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.642981</td>\n",
       "      <td>0.176821</td>\n",
       "      <td>-8.783283</td>\n",
       "      <td>-10.236029</td>\n",
       "      <td>-16.678669</td>\n",
       "      <td>-1.761115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      consensuality_scores  initial_consensuality_scores  listener_df  \\\n",
       "2017              0.652511                      0.182344    -9.367365   \n",
       "2018              1.051409                      0.436363   -17.345043   \n",
       "2019              1.053721                      0.425736   -16.270704   \n",
       "2020              0.642981                      0.176821    -8.783283   \n",
       "\n",
       "      speaker_df  language_model_proba_df  initial_listener  \n",
       "2017  -10.816949               -16.605637         -1.837223  \n",
       "2018  -19.487237               -18.474056         -2.303026  \n",
       "2019  -18.416813               -18.250831         -2.196775  \n",
       "2020  -10.236029               -16.678669         -1.761115  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_original = pd.concat(mean_scores_original, axis=1).transpose()\n",
    "concatenated_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_listener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orignal</th>\n",
       "      <td>0.850155</td>\n",
       "      <td>0.305316</td>\n",
       "      <td>-12.941599</td>\n",
       "      <td>-14.739257</td>\n",
       "      <td>-17.502298</td>\n",
       "      <td>-2.024535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         consensuality_scores  initial_consensuality_scores  listener_df  \\\n",
       "orignal              0.850155                      0.305316   -12.941599   \n",
       "\n",
       "         speaker_df  language_model_proba_df  initial_listener  \n",
       "orignal  -14.739257               -17.502298         -2.024535  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_original = pd.DataFrame(concatenated_original.mean()).transpose()\n",
    "res_original.index = ['orignal']\n",
    "res_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "mean_scores_gpt2 = {}\n",
    "\n",
    "for name, path in pickle_gpt2_paths.items():\n",
    "  print(name)\n",
    "  mean_scores_gpt2[name] =  extract_mean_scores(path).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_listener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1.092917</td>\n",
       "      <td>0.358979</td>\n",
       "      <td>-18.554302</td>\n",
       "      <td>-20.642376</td>\n",
       "      <td>-15.072538</td>\n",
       "      <td>-2.497087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1.060741</td>\n",
       "      <td>0.313634</td>\n",
       "      <td>-16.531683</td>\n",
       "      <td>-18.618351</td>\n",
       "      <td>-13.958208</td>\n",
       "      <td>-2.318736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1.060810</td>\n",
       "      <td>0.288102</td>\n",
       "      <td>-14.500072</td>\n",
       "      <td>-16.586401</td>\n",
       "      <td>-13.571649</td>\n",
       "      <td>-2.121807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>1.054152</td>\n",
       "      <td>0.272017</td>\n",
       "      <td>-13.837928</td>\n",
       "      <td>-15.923457</td>\n",
       "      <td>-13.039964</td>\n",
       "      <td>-2.060369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      consensuality_scores  initial_consensuality_scores  listener_df  \\\n",
       "2017              1.092917                      0.358979   -18.554302   \n",
       "2018              1.060741                      0.313634   -16.531683   \n",
       "2019              1.060810                      0.288102   -14.500072   \n",
       "2020              1.054152                      0.272017   -13.837928   \n",
       "\n",
       "      speaker_df  language_model_proba_df  initial_listener  \n",
       "2017  -20.642376               -15.072538         -2.497087  \n",
       "2018  -18.618351               -13.958208         -2.318736  \n",
       "2019  -16.586401               -13.571649         -2.121807  \n",
       "2020  -15.923457               -13.039964         -2.060369  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_gpt2 = pd.concat(mean_scores_gpt2, axis=1).transpose()\n",
    "concatenated_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consensuality_scores</th>\n",
       "      <th>initial_consensuality_scores</th>\n",
       "      <th>listener_df</th>\n",
       "      <th>speaker_df</th>\n",
       "      <th>language_model_proba_df</th>\n",
       "      <th>initial_listener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GPT2</th>\n",
       "      <td>1.067155</td>\n",
       "      <td>0.308183</td>\n",
       "      <td>-15.855996</td>\n",
       "      <td>-17.942646</td>\n",
       "      <td>-13.91059</td>\n",
       "      <td>-2.2495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      consensuality_scores  initial_consensuality_scores  listener_df  \\\n",
       "GPT2              1.067155                      0.308183   -15.855996   \n",
       "\n",
       "      speaker_df  language_model_proba_df  initial_listener  \n",
       "GPT2  -17.942646                -13.91059           -2.2495  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gpt2 = pd.DataFrame(concatenated_gpt2.mean()).transpose()\n",
    "res_gpt2.index = ['GPT2']\n",
    "res_gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_original_paths = { \n",
    "    \"2017\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-none-_-2024-12-12-18-26-05-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2018\" : \"output/extractive/extractive_sentences-_-all_reviews_2018-_-none-_-2025-02-10-08-15-21-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2019\" : \"output/extractive/extractive_sentences-_-all_reviews_2019-_-none-_-2025-02-08-18-51-24-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2020\" : \"output/extractive/extractive_sentences-_-all_reviews_2020-_-none-_-2025-02-09-00-02-38-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\"\n",
    "                          }\n",
    "\n",
    "pickle_cluster_2017_paths = {\n",
    "    \"2017-1\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-clustering-1-_-2025-02-03-14-03-32-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-3\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-clustering-3-_-2025-01-27-16-57-48-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-5\" : \"output/extractive/extractive_sentences-_-all_reviews_2019-_-cluster-_-2025-02-08-18-51-24-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-7\" : \"output/extractive/extractive_sentences-_-all_reviews_2020-_-cluster-_-2025-02-09-00-02-38-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-10\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-clustering-10-_-2024-12-20-12-02-07-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\"\n",
    "}\n",
    "\n",
    "pickle_tfidf_2017_paths = {\n",
    "    \"2017-1\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-top_sentences-1-_-2025-02-03-15-18-16-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-3\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-top_sentences-3-_-2025-01-27-09-35-07-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-5\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-top_sentences-5-_-2025-01-27-08-38-44-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-7\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-top_sentences-7-_-2025-02-03-15-31-56-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-10\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-top_sentences-10-_-2025-01-26-17-10-07-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "}\n",
    "\n",
    "pickle_tfidf_2018_paths = {\n",
    "    \"2018-3\" : \"output/extractive/extractive_sentences-_-all_reviews_2018-_-top_sentences-3-_-2025-02-08-11-31-20-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2018-5\" : \"output/extractive/extractive_sentences-_-all_reviews_2018-_-top_sentences-5-_-2025-02-10-16-15-53-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2018-7\" : \"output/extractive/extractive_sentences-_-all_reviews_2018-_-top_sentences-7-_-2025-02-10-10-48-00-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    }\n",
    "\n",
    "pickle_tfidf_2019_paths = {\n",
    "    \"2019-3\" : \"output/extractive/extractive_sentences-_-all_reviews_2019-_-top_sentences-3-_-2025-02-08-22-43-24-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2019-5\" : \"output/extractive/extractive_sentences-_-all_reviews_2019-_-top_sentences-5-_-2025-02-10-15-37-51-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2019-7\" : \"output/extractive/extractive_sentences-_-all_reviews_2019-_-top_sentences-7-_-2025-02-08-23-07-10-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    }\n",
    "\n",
    "pickle_tfidf_2020_paths = {\n",
    "    \"2020-3\" : \"output/extractive/extractive_sentences-_-all_reviews_2020-_-top_sentences-3-_-2025-02-10-11-57-48-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2020-5\" : \"output/extractive/extractive_sentences-_-all_reviews_2020-_-top_sentences-5-_-2025-02-10-14-34-58-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2020-7\" : \"output/extractive/extractive_sentences-_-all_reviews_2020-_-top_sentences-7-_-2025-02-10-12-57-30-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    }\n",
    "\n",
    "pickle_dynamic_tfidf_2017_paths = {\n",
    "    \"2017-0.1\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-dynamic_tfidf_0.1-_-2025-02-06-09-19-46-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-0.3\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-dynamic_tfidf_0.3-_-2025-02-05-10-55-40-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-0.5\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-dynamic_tfidf_0.5-_-2025-02-05-10-02-50-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "    \"2017-0.7\" : \"output/extractive/extractive_sentences-_-all_reviews_2017-_-dynamic_tfidf_0.7-_-2025-02-06-14-37-02-_-r3-_-rsa_reranked-google-pegasus-arxiv.pk\",\n",
    "}\n",
    "\n",
    "dict_dict_of_paths = {\n",
    "    \"original\" : pickle_original_paths,\n",
    "    \"cluster_2017\" : pickle_cluster_2017_paths,\n",
    "    \"tfidf_2017\" : pickle_tfidf_2017_paths,\n",
    "    \"tfidf_2018\" : pickle_tfidf_2018_paths,\n",
    "    \"tfidf_2019\" : pickle_tfidf_2019_paths,\n",
    "    \"tfidf_2020\" : pickle_tfidf_2020_paths,\n",
    "    \"dynamic_tfidf_2017\" : pickle_dynamic_tfidf_2017_paths\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dict_of_paths in dict_dict_of_paths.items():\n",
    "    print(name)\n",
    "    mean_scores_all = {}\n",
    "    for name, path in dict_of_paths.items():\n",
    "        print(name)\n",
    "        mean_scores_all[name] =  extract_mean_scores(path).mean()\n",
    "        concatenated_all = pd.concat(mean_scores_all, axis=1).transpose()\n",
    "    res_all = pd.DataFrame(concatenated_all.mean()).transpose()\n",
    "    res_all.index = ['name']\n",
    "    display(res_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Rouge Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstractive\n",
    "datasets = {\n",
    "    \"2017_original_abstractive\" : \"data/candidates/facebook_bart-large-cnn-_-all_reviews_2017-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37.csv.csv\",\n",
    "    \"2018_original_abstractive\" : \"data/candidates/facebook_bart-large-cnn-_-all_reviews_2018-_-top_p_sampling-_-padded-_-2024-12-09-13-08-21.csv\",\n",
    "    \"2019_original_abstractive\" : \"data/candidates/facebook_bart-large-cnn-_-all_reviews_2019-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37.csv\",\n",
    "    \"2020_original_abstractive\" : \"data/candidates/facebook_bart-large-cnn-_-all_reviews_2020-_-top_p_sampling-_-trimmed-_-2024-12-11-15-31-37.csv\",\n",
    "    \"2017_modified_abstractive\" : \"data/candidates/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2017-_-top_p_sampling-_-trimmed-_-2025-02-08-22-07-53.csv\",\n",
    "    \"2018_modified_abstractive\" : \"data/candidates/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2018-_-top_p_sampling-_-trimmed-_-2025-02-08-23-18-26.csv\",\n",
    "    \"2019_modified_abstractive\" : \"data/candidates/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2019-_-top_p_sampling-_-trimmed-_-2025-02-09-01-34-19.csv\",\n",
    "    \"2020_modified_abstractive\" : \"data/candidates/gavin124_gpt2-finetuned-cnn-summarization-v2-_-all_reviews_2020-_-top_p_sampling-_-trimmed-_-2025-02-09-10-18-19.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Rouge and Mean Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in datasets.items():\n",
    "  print(name)\n",
    "  # Load dataset (CSV file should have 'gold' and 'summary' columns)\n",
    "  df = pd.read_csv(path)\n",
    "\n",
    "  # Compute ROUGE scores\n",
    "  rouge_scores = evaluate_rouge(df)\n",
    "\n",
    "  # Print results\n",
    "  final_scores = pd.DataFrame({\n",
    "      \"Rouge-1\": rouge_scores[\"rouge1\"],\n",
    "      \"Rouge-2\": rouge_scores[\"rouge2\"],\n",
    "      \"Rouge-L\": rouge_scores[\"rougeL\"]})\n",
    "  scores_dict[name] = final_scores.copy()\n",
    "  scores_dict[name].to_csv(f\"output/abstractive/rouge/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, score_df in scores_dict.items():\n",
    "  print(name)\n",
    "  score_df_mean = score_df.mean()\n",
    "  #display(score_df_mean)\n",
    "  score_df_mean.to_csv(f\"output/abstractive/rouge/mean/{name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractive\n",
    "extractive_dir = 'data/candidates/extractive'\n",
    "extractive_files = [os.path.join(extractive_dir, file) for file in os.listdir(extractive_dir) if os.path.isfile(os.path.join(extractive_dir, file))]\n",
    "for i in range(len(extractive_files)):\n",
    "    name = (extractive_files[i].split('-_-')[1] + \"-\" + extractive_files[i].split('-_-')[2]).split('_')[2]\n",
    "    path = extractive_files[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Rouge and Mean Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, path in datasets.items():\n",
    "  print(name)\n",
    "  # Load dataset (CSV file should have 'gold' and 'summary' columns)\n",
    "  df = pd.read_csv(path)\n",
    "\n",
    "  # Compute ROUGE scores\n",
    "  rouge_scores = evaluate_rouge(df)\n",
    "\n",
    "  # Print results\n",
    "  final_scores = pd.DataFrame({\n",
    "      \"Rouge-1\": rouge_scores[\"rouge1\"],\n",
    "      \"Rouge-2\": rouge_scores[\"rouge2\"],\n",
    "      \"Rouge-L\": rouge_scores[\"rougeL\"]})\n",
    "  scores_dict[name] = final_scores.copy()\n",
    "  scores_dict[name].to_csv(f\"output/extractive/rouge/{name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, score_df in scores_dict.items():\n",
    "  print(name)\n",
    "  score_df_mean = score_df.mean()\n",
    "  #display(score_df_mean)\n",
    "  score_df_mean.to_csv(f\"output/extractive/rouge/mean/{name}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
